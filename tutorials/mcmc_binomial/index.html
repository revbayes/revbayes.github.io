<!doctype html>
<html lang="en">
<link rel="icon" type="image/png" href="/assets/img/favicon.png" >
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="search-domain" value="https://revbayes.github.io/">
    <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css" />
    <title>RevBayes: Introduction to MCMC using RevBayes</title>
  </head>
  <body>
    <div class="container">
      <nav class="navbar navbar-default">
  <div class="container-fluid">
    <div class="navbar-header">
      <a href="/" class="pull-left">
        
        <img class="navbar-logo" src="/assets/img/aquabayes-desaturated.png" alt="RevBayes Home" />
        
      </a>
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar" align="right"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="/software">Software</a></li>
        <li><a href="/tutorials/">Tutorials</a></li>
        <li><a href="/workshops/">Workshops</a></li>
        <li><a href="/developer/">Developer</a></li>
      </ul>
      <!-- <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form> -->
    </div>
  </div>
</nav>

      <div class="titlebar">
	<h1 class="maintitle">Introduction to MCMC using RevBayes</h1>
	<h3 class="subtitle">Introduction to MCMC Simulation using a simple Binomial Model</h3>
	<h4 class="authors">Mike May, Brian Moore and Sebastian H&#246;hna</h4>
</div>


<div class="sidebar no-print">
<blockquote class="overview" id="overview">
  <h2>Overview</h2>
  
  <div class="row">
    <div class="col-md-9">
        <strong>Prerequisites</strong>
        
          <ul id="prerequisites">
          
            <li><a href="/tutorials/intro/">Rev Language Syntax</a></li>
          
          </ul>
        
    </div>
  </div>
  
</blockquote>





</div>
<h1 id="overview">Overview</h1>

<p>This very basic tutorial provides an introduction to Bayesian inference
and Markov chain Monte Carlo (MCMC) algorithms. The tutorial explains
the fundamental concepts of an MCMC algorithm, such as <em>moves</em> and
<em>monitors</em>, which are ubiquitous in every other tutorial. After the
tutorial you should be somewhat familiar with Bayesian inference
(<em>e.g.</em>, what is a prior distribution,
posterior distribution, and likelihood function) and MCMC simulation
(<em>e.g.</em>, what are moves and monitors and why do
we need them).</p>

<h1 id="a-coin-flipping-binomial-model">A Coin Flipping (Binomial) Model</h1>

<p>We’ll begin our exploration of Bayesian inference with a simple
coin-flipping model. In this model, we imagine flipping a coin $n$ times
and count the number of heads, $x$; each flip comes up heads with
probability $p$. This model gives rise to the Binomial probability
distribution, with parameters $n$ and $p$: <script type="math/tex">\begin{aligned}
P(x \mid n,p) = {n \choose x}p^x(1-p)^{n-x}\end{aligned}</script> Simple
intuition suggests that, given that we observe $x$ heads in $n$ coin
tosses, the maximum-likelihood estimate (MLE) of $p$ is simply
$\frac{x}{n}$: if we flip a coin 100 times and observe 70 heads, we
assume the probability the coin comes up heads is
$\frac{70}{100} = 0.7$. This is indeed the maximum likelihood estimate!</p>

<p>From Bayes’ theorem, the <em>posterior distribution</em> of $p$ given $x$,
$P(p \mid x)$, is: <script type="math/tex">\begin{aligned\frac{
}{b}ace{P(p \mid x)}^{\text{posterior distribution}} = \frac\frac{ }{b}ace{P(x \mid p)}^{\text{likelihood}} \time\frac{ }{b}ace{P(p)}^{\text{prior}}}{\underbrace{P(x)}_{\text{marginal likelihood}}}\end{aligned}</script>
The take-home message here is that, if we’re interested in doing
Bayesian inference for the coin flipping model, we need to specify a
<em>likelihood function</em> and a <em>prior distribution</em> for $p$. In virtually
all practical cases, we cannot compute the posterior distribution
directly and instead use numerical procedures, such as a Markov chain
Monte Carlo (MCMC) algorithm. Therefore, we will also have to write an
MCMC algorithm that samples parameter values in the frequency of their
posterior probability.</p>

<p>We’ll use a simple beta distribution as a prior on the parameter of the
model, $p$. The beta distribution has two parameters, $\alpha$ and
$\beta$ (Figure [fig:beta_distribution]). Different choices for
$\alpha$ and $\beta$ represent different prior beliefs.</p>

<p>[fig:beta_distribution]</p>

<blockquote class="figure">
  <p><img src="figures/beta.png" alt="" /> 
distribution with two parameters,
$\alpha$ and $\beta$. This distribution is used as a prior distribution
on the probability parameter $p$ of observing a head. Here we show
different curves for the beta distribution when using different
parameters.</p>
</blockquote>

<p>Figure [fig:binomial_model] shows the graphical model for the
binomial model. This nicely visualizes the dependency structure in the
model. We see that the two parameters $\alpha$ and $\beta$ are drawn in
solid squares, representing that these variables are constant. From
these two variables, we see arrows going into the variable $p$. That
simply means that $p$ depends on $\alpha$ and $\beta$. More
specifically, $p$ is a stochastic variable (shown as a solid circle) and
drawn from a beta distribution with parameters $\alpha$ and $\beta$.
Then, we have another constant variable, $n$. Finally, we have the
observed data $x$ which is drawn from a Binomial distribution with
parameters $p$ and $n$, as can be seen by the arrows going into $x$.
Furthermore, the solid circle of $x$ is shaded which means that the
variable has data attached to it.</p>

<p>[fig:binomial_model]</p>

<blockquote class="figure">
  <p><img src="figures/binomial_graphical_model.png" alt="" /> 
ical model
for the binomial model.</p>
</blockquote>

<h1 id="writing-an-mcmc-from-scratch">Writing an MCMC from Scratch</h1>

<p>Make yourself familiar with the example script called
<em>Binomial_MH_algorithm.Rev</em> which shows the code for the following
sections. Then, start a new and empty script and follow each step
provided in the .</p>

<h2 id="the-metropolis-hastings-algorithm">The Metropolis-Hastings Algorithm</h2>

<p>Though RevBayes implements efficient and easy-to-use Markov chain
Monte Carlo algorithms, we’ll begin by writing one ourselves to gain a
better understanding of the moving parts. The Metropolis-Hastings MCMC
algorithm (missing reference) proceeds as follows:</p>

<ol>
  <li>
    <p>Generate initial values for the parameters of the model (in this
case, $p$).</p>
  </li>
  <li>
    <p>Propose a new value (which we’ll call $p^\prime$) for some
parameters of the model, (possibly) based on their current values</p>
  </li>
  <li>
    <p>Calculate the acceptance probability, $R$, according to:
<script type="math/tex">\begin{aligned}
		R = \text{min}\left\{1, \frac{P(x \mid p^\prime)}{P(x \mid p)} \times \frac{P(p^\prime)}{P(p)} \times \frac{q(p)}{q(p^\prime)} \right\}
	\end{aligned}</script></p>
  </li>
  <li>
    <p>Generate a uniform random number between 1 and 0. If it is less than
$R$, accept the move (set $p = p^\prime$). Otherwise, keep the
current value of $p$.</p>
  </li>
  <li>
    <p>Record the values of the parameters.</p>
  </li>
  <li>
    <p>Return to step 2 many many times, keeping track of the value of $p$.</p>
  </li>
</ol>

<h2 id="reading-in-the-data">Reading in the data</h2>

<p>Actually, in this case, we’re just going to make up some data on the
spot. Feel free to alter these values to see how they influence the
posterior distribution</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Make up some coin flips!
# Feel free to change these numbers
n &lt;- 100 # the number of flips
x &lt;- 63	# the number of heads
</code></pre></div></div>

<h2 id="initializing-the-markov-chain">Initializing the Markov chain</h2>

<p>We have to start the MCMC off with some initial parameter values. One
way to do this is to randomly draw values of the parameters (just $p$,
in this case) from the prior distribution. We’ll assume a “flat” beta
prior distribution; that is, one with parameters $\alpha = 1$ and
$\beta = 1$.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Initialize the chain with starting values
alpha &lt;- 1
beta  &lt;- 1
p &lt;- rbeta(n=1,alpha,beta)[1]
</code></pre></div></div>

<h3 id="likelihood-function">Likelihood function</h3>

<p>We also need to specify the likelihood function. We use the binomial
probability for the likelihood function. Since the likelihood is defined
only for values of $p$ between 0 and 1, we return 0.0 if $p$ is outside
this range:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># specify the likelihood function
function likelihood(p) {
    if(p &lt; 0 || p &gt; 1)
        return 0

    l = dbinomial(x,p,n,log=false)
    return l
}
</code></pre></div></div>

<h3 id="prior-distribution">Prior distribution</h3>

<p>Similarly, we need to specify a function for the prior distribution.
Here, we use the beta probability distribution for the prior on $p$:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># specify the prior function
function prior(p) {
    if(p &lt; 0 || p &gt; 1)
        return 0
        
    pp = dbeta(p,alpha,beta,log=false)
    return pp
}
</code></pre></div></div>

<h3 id="monitoring-parameter-values">Monitoring parameter values</h3>

<p>Additionally, we are going to monitor,
<em>i.e.</em>, store, parameter values into a file
during the MCMC simulation. For this file we need to write the column
headers:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Prepare a file to log our samples
write("iteration","p","\n",file="binomial_MH.log")
write(0,p,"\n",file="binomial_MH.log",append=TRUE)
</code></pre></div></div>

<p>(You may have to change the newline characters to
<code class="highlighter-rouge">\backslashr\backslashn</code> if you’re using a Windows operating system.)
We’ll also monitor the parameter values to the screen, so let’s print
the initial values:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Print the initial values to the screen
print("iteration","p")
print(0,p)
</code></pre></div></div>

<h2 id="writing-the-mh-algorithm">Writing the MH Algorithm</h2>

<p>At long last, we can write our MCMC algorithm. First, let us define the
frequency how often we print to file
(<em>i.e.</em>, monitor), which is also often called
thinning. If we set the variable <code class="highlighter-rouge">printgen</code> to 1, then we will store the
parameter values every single iteration; if we choose <code class="highlighter-rouge">printgen=10</code>
instead, then only every $10^{th}$ iteration.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>printgen = 10
</code></pre></div></div>

<p>We will repeat this resampling procedure many times (here, 10000), and
iterate the MCMC using a <code class="highlighter-rouge">for</code> loop:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Write the MH algorithm
reps = 10000 
for(rep in 1:reps){
</code></pre></div></div>

<p>(remember to close your <code class="highlighter-rouge">for</code> loop at the end).</p>

<p>The first thing we do in the first generation is generate a new value of
$p^\prime$ to evaluate. We’ll propose a new value of $p$ from a uniform
distribution between 0 and 1. Note that in this first example we do not
condition new parameter values on the current value.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	# Propose a new value of p
	p_prime &lt;- runif(n=1,0.0,1.0)[1]
</code></pre></div></div>

<p>Next, we compute the proposed likelihood and prior probabilities, as
well as the acceptance probability, $R$:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	# Compute the acceptance probability
	R &lt;- ( likelihood(p_prime) / likelihood(p) ) * ( prior(p_prime) / prior(p) )
</code></pre></div></div>

<p>Then, we accept the proposal with probability $R$ and reject otherwise:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>	# Accept or reject the proposal
	u &lt;- runif(1,0,1)[1]
	if(u &lt; R){
		# Accept the proposal
		p &lt;- p_prime
	}
</code></pre></div></div>

<p>Finally, we store the current value of $p$ in our log file. Here, we
actually check if we want to store the value during this iteration.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    if ( (rep % printgen) == 0 ) {
        # Write the samples to a file
        write(rep,p,"\n",file="binomial_MH.log",append=TRUE)
        # Print the samples to the screen
        print(rep,p)
    }
} # end MCMC
</code></pre></div></div>

<h2 id="visualizing-the-samples-of-an-mcmc-simulation">Visualizing the samples of an MCMC simulation</h2>

<p>Below we show an example of the obtained output in
<code class="highlighter-rouge">Tracer</code>. Specifically, Figure [fig:mcmc_samples] shows
the sample trace (left) and the estimated posterior distribution of $p$
(right). There are other parameters, such as the posterior mean and the
95% HPD (highest posterior density) interval, that you can obtain from
<code class="highlighter-rouge">Tracer</code>.</p>

<p>[fig:mcmc_samples]</p>

<blockquote class="figure">
  <p><img src="figures/binomial_MCMC_Trace.png" alt="" /> &gt;
<img src="figures/binomial_MCMC_distribution.png" alt="" /> 
he <em>Trace</em> of
sample from an MCMC simulation. Right: The approximated posterior
probability distribution for $p$.</p>
</blockquote>

<h1 id="more-on-moves-tuning-and-weights">More on Moves: Tuning and weights</h1>

<p>In the previous example we hard coded a single move updating the
variable $p$ by drawing a new value from a uniform(0,1) distribution.
There are actually many other ways how to propose new values; some of
which are more efficient than others.</p>

<p>First, let us rewrite the MCMC loop so that we use instead a function,
which we call <code class="highlighter-rouge">move_uniform</code> for simplicity, that performs the move:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for (rep in 1:reps){
    
    # call uniform move
    move_uniform(1)
    
    if ( (rep % printgen) == 0 ) {
        # Write the samples to a file
        write(rep,p,"\n",file="binomial_MH.log",append=TRUE)
    }

} # end MCMC
</code></pre></div></div>

<p>This loop looks already much cleaner.</p>

<h2 id="uniform-move">Uniform move</h2>

<p>Now we need to actually write the <code class="highlighter-rouge">move_uniform</code> function. We mostly
just copy the code we had before into a dedicated function</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function move_uniform( Natural weight) {

    for (i in 1:weight) {
        # Propose a new value of p
        p_prime &lt;- runif(n=1,0.0,1.0)[1]

        # Compute the acceptance probability
        R &lt;- ( likelihood(p_prime) / likelihood(p) ) * ( prior(p_prime) / prior(p) )
    
        # Accept or reject the proposal
        u &lt;- runif(1,0,1)[1]
        if (u &lt; R){
            # Accept the proposal
            p &lt;- p_prime
        } else {
            # Reject the proposal
            # (we don't have to do anything here)
        }
    }
    
}
</code></pre></div></div>

<p>There are a few things to consider in the function <code class="highlighter-rouge">move_uniform</code>.
First, we do not have a return value because the move simply changes the
variable $p$ if the move is accepted. Second, we expect an argument
called <code class="highlighter-rouge">weight</code> which will tell us how often we want to use this move.
Otherwise, this function does exactly the same what was inside the for
loop previously.</p>

<p>(Note that you need to define this function before the for loop in your
script).</p>

<h2 id="sliding-window-move">Sliding-window move</h2>

<p>As a second move we will write a sliding-window move. The sliding-window
moves propose an update by drawing a random number from a uniform
distribution and then adding this random number to the current value
(<em>i.e.</em>, centered on the previous value).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function move_slide( RealPos delta, Natural weight) {

    for (i in 1:weight) {
        # Propose a new value of p
        p_prime &lt;- p + runiform(n=1,-delta,delta)[1]

        # Compute the acceptance probability
        R &lt;- ( likelihood(p_prime) / likelihood(p) ) * ( prior(p_prime) / prior(p) )
    
        # Accept or reject the proposal
        u &lt;- runif(1,0,1)[1]
        if (u &lt; R) {
            # Accept the proposal
            p &lt;- p_prime
        } else {
            # Reject the proposal
            # (we don't have to do anything here)
        }
    }
    
}
</code></pre></div></div>

<p>In addition to the weight of the move, this move has another argument,
<code class="highlighter-rouge">delta</code>. The argument <code class="highlighter-rouge">delta</code> defines the width of the uniform window
from which we draw new values. Thus, if <code class="highlighter-rouge">delta</code> is large, then the
proposed values are more likely to be very different from the current
value of $p$. Conversely, if <code class="highlighter-rouge">delta</code> is small, then the proposed values
are more likely to be very close to the current value of $p$.</p>

<p>Experiment with different values for <code class="highlighter-rouge">delta</code> and check how the effective
sample size (ESS) changes.</p>

<p>There is, a priori, no good method for knowing what values of <code class="highlighter-rouge">delta</code>
are most efficient. However, there are some algorithms implemented in
RevBayes, called <em>auto-tuning</em>, that will estimate good values for
<code class="highlighter-rouge">delta</code>.</p>

<h2 id="scaling-move">Scaling move</h2>

<p>As a third and final move we will write a scaling move. The scaling move
proposes an update by drawing a random number from a uniform(-0.5,0.5)
distribution, exponentiating the random number, and then multiplying
this scaling factor by the current value. An interesting feature of this
move is that it is not symmetrical and thus needs a Hastings ratio. The
Hastings ratio is rather trivial in this case, and one only needs to
multiply the acceptance rate by the scaling factor.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>function move_scale( RealPos lambda, Natural weight) {

    for (i in 1:weight) {
        # Propose a new value of p
        sf &lt;- exp( lambda * ( runif(n=1,0,1)[1] - 0.5 ) )
        p_prime &lt;- p * sf

        # Compute the acceptance probability
        R &lt;- ( likelihood(p_prime) / likelihood(p) ) * ( prior(p_prime) / prior(p) ) * sf
    
        # Accept or reject the proposal
        u &lt;- runif(1,0,1)[1]
        if (u &lt; R){
            # Accept the proposal
            p &lt;- p_prime
        } else {
            # Reject the proposal
            # (we don't have to do anything here)
        }
    }
    
}
</code></pre></div></div>

<p>As before, this move has a tuning parameter called <em>lambda</em>.</p>

<p>The sliding-window and scaling moves are very common and popular moves
in RevBayes. The code examples here are actually showing the exact
same equation as implemented internally. It will be very useful for you
to understand these moves.</p>

<p>However, this MCMC algorithm is <em>very</em> specific to our binomial model
and thus hard to extend (also it’s pretty inefficient!).</p>

<h1 id="the-metropolis-hastings-algorithm-with-the-real-revbayes">The Metropolis-Hastings Algorithm with the <em>Real</em> RevBayes</h1>

<p>We’ll now specify the exact same model in <code class="highlighter-rouge">Rev</code> using the built-in
modeling functionality. It turns out that the <code class="highlighter-rouge">Rev</code> code to specify the
above model is extremely simple and similar to the one we used before.
Again, we start by “reading in” (<em>i.e.</em>, making up) our data.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Make up some coin flips!
# Feel free to change these numbers
n &lt;- 100 # the number of flips
x &lt;- 63	# the number of heads
</code></pre></div></div>

<p>Now we specify our prior model.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Specify the prior distribution
alpha &lt;- 1
beta  &lt;- 1
p ~ dnBeta(alpha,beta)
</code></pre></div></div>

<p>One difference between RevBayes and the MH algorithm that we wrote
above is that many MCMC proposals are already built-in, but we have to
specify them <em>before</em> we run the MCMC. We usually define (at least) one
move per parameter immediately after we specify the prior distribution
for that parameter.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Define a move for our parameter, p
moves[1] = mvSlide(p,delta=0.1,weight=1)
</code></pre></div></div>

<p>Next, our likelihood model.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Specify the likelihood model
k ~ dnBinomial(p, n)
k.clamp(x)
</code></pre></div></div>

<p>We wrap our full Bayesian model into one model object (this is a
convenience to keep the entire model in a single object, and is more
useful when we have very large models):</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Construct the full model
my_model = model(p)
</code></pre></div></div>

<p>We use “monitors” to keep track of parameters throughout the MCMC. The
two kinds of monitors we use here are the <code class="highlighter-rouge">mnModel</code>, which writes
parameters to a specified file, and the <code class="highlighter-rouge">mnScreen</code>, which simply outputs
some parts of the model to screen (as a sort of progress bar).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Make the monitors to keep track of the MCMC
monitors[1] = mnModel(filename="binomial_MCMC.log", printgen=10, separator = TAB)
monitors[2] = mnScreen(printgen=100, p)
</code></pre></div></div>

<p>Finally, we assemble the analysis object (which contains the model, the
monitors, and the moves) and execute the run using the <code class="highlighter-rouge">.run</code> command:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Make the analysis object
analysis = mcmc(my_model, monitors, moves)

# Run the MCMC
analysis.run(100000)

# Show how the moves performed
analysis.operatorSummary()
</code></pre></div></div>

<p>Open the resulting <code class="highlighter-rouge">binomial_MCMC.log</code> file in <code class="highlighter-rouge">Tracer</code>. Do the
posterior distributions for the parameter $p$ look the same as the ones
we got from our first analysis?</p>

<p>Hopefully, you’ll note that this <code class="highlighter-rouge">Rev</code> model is substantially simpler
and easier to read than the MH algorithm script we began with. Perhaps
more importantly, this <code class="highlighter-rouge">Rev</code> analysis is <em>orders of magnitude</em> faster
than our own script, because it makes use of extremely efficient
probability calculations built-in to RevBayes (rather than the ones we
hacked together in our own algorithm).</p>

<h1 id="exercises-for-the-mcmc-tutorial">Exercises for the MCMC Tutorial</h1>

<h2 id="exercise-1-performing-your-first-simple-mcmc-simulation">Exercise 1: Performing your first simple MCMC simulation</h2>

<ol>
  <li>
    <p>Look into the <em>Binomial_MH_algorithm.Rev</em> script and make yourself
familiar with it. All the commands should be explained in the text
of the tutorial.</p>
  </li>
  <li>
    <p>Execute the script <em>Binomial_MH_algorithm.Rev</em>).</p>
  </li>
  <li>
    <p>The <code class="highlighter-rouge">.log</code> file will contain samples from the posterior distribution
of the model! Open the file in <code class="highlighter-rouge">Tracer</code>to learn about
various features of the posterior distribution, for example: the
posterior mean or the 95% credible interval.</p>
  </li>
  <li>
    <p>Save the MCMC trace plot and posterior distribution into a PDF file
and upload the files. Write here the name of your file:\</p>
  </li>
</ol>

<h2 id="exercise-2-different-mcmc-strategies-moves">Exercise 2: Different MCMC strategies (moves)</h2>

<ol>
  <li>
    <p>Now look into the script called <em>Binomial_MH_algorithm_moves.Rev</em>
which shows the 3 different types of moves described in
this tutorial.</p>
  </li>
  <li>
    <p>Run the script to estimate the posterior distribution of $p$ again.</p>
  </li>
  <li>
    <p>Look at the output in <code class="highlighter-rouge">Tracer</code>.</p>
  </li>
  <li>
    <p>Use only a single move and set <code class="highlighter-rouge">printgen=1</code>. Which move has the best
ESS? Enter the ESS values for the different moves here:\</p>
  </li>
  <li>
    <p>How does the ESS change if you use a <code class="highlighter-rouge">delta=10</code> for the
sliding-window move?\</p>
  </li>
  <li>
    <p>Add to each move a counter variable that counts how often the move
was accepted. For example:</p>

    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        if (u &lt; R){
            # Accept the proposal
            p &lt;- p_prime
            ++num_sliding_move_accepted
        } 
</code></pre></div>    </div>
  </li>
  <li>
    <p>Have a look at how the acceptance rate changes for different values
of the tuning parameters.\</p>
  </li>
</ol>

<h2 id="exercise-3-mcmc-in-revbayes">Exercise 3: MCMC in RevBayes</h2>

<ol>
  <li>
    <p>Run the built-in MCMC (<em>Binomial_MCMC.Rev</em>) and compare the results
to your own MCMC. Are the posterior estimates the same? Are the ESS
values similar? Which script was the fastest?\</p>
  </li>
  <li>
    <p>Next, add a second move <code class="highlighter-rouge">moves[2] =
mvScale(p,lambda=0.1,tune=true,weight=1.0)</code> just after the
first one.</p>
  </li>
  <li>
    <p>Run the analysis again and upload your trace file. Write here the
name of your file:\</p>
  </li>
  <li>
    <p>Finally, run a pre-burnin using
<code class="highlighter-rouge">analysis.burnin(generations=10000,tuningInterval=200)</code> just before
you call <code class="highlighter-rouge">analysis.run(100000)</code>. This will auto-tune the tuning
parameters (<em>e.g.</em>, <code class="highlighter-rouge">delta</code> and <code class="highlighter-rouge">lambda</code>)
so that the acceptance ratio is between 0.4 and 0.5.</p>
  </li>
  <li>
    <p>What are the tuned values for <code class="highlighter-rouge">delta</code> and <code class="highlighter-rouge">lambda</code>? Did the
auto-tuning increase the ESS?\</p>
  </li>
</ol>

<h2 id="exercise-4-approximating-the-posterior-distribution">Exercise 4: Approximating the posterior distribution</h2>

<p>Modify the script <em>Binomial_MCMC.Rev</em>. Assume you flipped a coin 100
times and got 34 heads. Run the MCMC for 100,000 generations, printing
every 100 samples to the file.</p>

<ol>
  <li>
    <p>What is the posterior mean estimate of p? The 95% credible
interval?\</p>
  </li>
  <li>
    <p>Pretend you flipped the coin 900 more times, for a total of
1000 flips. Among those 1000 flips, you observed 340 heads (change
your script accordingly!). What is your posterior mean estimate of p
now? How has the 95% credible interval changed? Provide an intuitive
explanation for this change.\</p>
  </li>
</ol>

<h2 id="exercise-5-exploring-prior-sensitivity-and-mcmc-settings">Exercise 5: Exploring prior sensitivity and MCMC settings</h2>

<p>Play around with various parts of the model to develop on intuition for
both the Bayesian model and the MCMC algorithm. For example, how does
the posterior distribution change as you increase the number of coin
flips (say, increase both the number of flips and the number of heads by
an order of magnitude)? How does the estimated posterior distribution
change if you change the prior model parameters, $\alpha$ and $\beta$
(<em>i.e.</em>, is the model prior sensitive)? Does
the prior sensitivity depend on the sample size? Are the posterior
estimates sensitive to the length of the MCMC? Do you think this MCMC
has been run sufficiently long, or should you run it longer? Try to
answer some of these questions and explain your finding here:\</p>


<ol class="bibliography"></ol>

<script type="text/javascript">
var _ol = document.querySelectorAll('ol');
for (var i = 0, elem_ol; elem_ol = _ol[i]; i++) {
	if ( elem_ol.classList == "bibliography" ) {
		var _li = elem_ol.getElementsByTagName("li");
		//for (var j = 0, elem_li; elem_li = _li[j]; j++)
		//{
		//	elem_li.innerHTML = elem_li.innerHTML.replace(/(https?:\/\/)([^\s<]+)/,"<a href=\"$1$2\">$2");
		//}
		if(_li.length > 0)
			elem_ol.outerHTML = "<h2 class='references'>References</h2><hr class='references'>"+elem_ol.outerHTML
	}
}
</script>

      <br>
<footer>
  <div class="container">
  <div class="row">
    <div class="col-sm-12" align="center">
      <a href="https://github.com/revbayes">GitHub</a> | <a href="/license">License</a> | <a href="/citation">Citation</a> | <a href="https://groups.google.com/forum/#!forum/revbayes-users">Users Forum</a>
    </div>
  </div>
  <br>
  </div>
</footer>

    </div>
    <script src="/assets/js/vendor/jquery.min.js"></script>
<script src="/assets/js/vendor/FileSaver.min.js"></script>
<script src="/assets/js/vendor/jszip.min.js"></script>
<script src="/assets/js/vendor/bootstrap.min.js"></script>

<script type="text/javascript">
// Add default language
$(":not(code).highlighter-rouge").each(function() {
  
  if( this.classList == "highlighter-rouge") {
    this.classList = "Rev highlighter-rouge";
  }
  
});
// $("code.highlighter-rouge").each(function() {
//   
//   if( this.classList == "highlighter-rouge") {
//       this.classList = "Rev highlighter-rouge";
//   }
//   
// });
</script>

<script src="/assets/js/base.js"></script>

<script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
</script>

  </body>
</html>
