<!doctype html>
<html lang="en">
<link rel="icon" type="image/png" href="/assets/img/favicon.png" >
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="search-domain" value="https://revbayes.github.io/">
    <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet">
    <link rel="stylesheet" href="/assets/css/syntax.css">
    <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/bootstrap-theme.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/main.css" />
    <title>RevBayes: Introduction to Graphical Models</title>
  </head>
  <body>
    <div class="container">
      <nav class="navbar navbar-default navbar-fixed-top">
  <div class="container-fluid">
    <div class="navbar-header">
      <a href="/" class="pull-left">
        
        <img class="navbar-logo" src="/assets/img/aquabayes-desaturated.png" alt="RevBayes Home" />
        
      </a>

      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar" align="right"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

    </div>
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
      <ul class="nav navbar-nav">
        <li><a href="/download">Download</a></li>
        <li><a href="/tutorials/">Tutorials</a></li>
        <li><a href="/documentation/">Documentation</a></li>
        <li><a href="/interfaces">Interfaces</a></li>
        <li><a href="/workshops/">Workshops</a></li>
        <li><a href="/jobs/">Jobs</a></li>
        <li><a href="/developer/">Developer</a></li>
        <li><class="header-search">
  <form class="header-search-form" action="/search.html" method="get">
    <input type="text" id="search-box-nav" placeholder="Search..." name="query" style="border-color:black;background-color:white;height:32px;">
    <button type="submit" style="color:black; border-color:black;width:32px;height:32px;padding-top:4px">
        <img src="https://revbayes.github.io/assets/img/search.png" height="22px" width="28px"/>
    </button>
  </form>
</div>

</li>
      </ul>
      <!-- <form class="navbar-form navbar-right" role="search" id="search" onsubmit="google_search(); return false;">
        <div class="form-group">
          <input type="text" id="google-search" placeholder="Search..." aria-label="Google site search">
        </div>
      </form> -->
    </div>
  </div>
</nav>

      <!-- adds margin to main content -->
      <div class="container">
          <div class="titlebar">
	<h1 class="maintitle">Introduction to Graphical Models</h1>
	<h3 class="subtitle">A gentle introduction to graphical models, probabilistic programming, and MCMC using a simple linear regression example.</h3>
	<h4 class="authors">Will Freyman</h4>
  <h5>Last modified on June  2, 2024</h5>
</div>


<div class="sidebar no-print">
<blockquote class="overview" id="overview">
  <h2>Overview</h2>
  
  <div class="row">
    <div class="col-md-9">
        <strong>Prerequisites</strong>
        
          <ul id="prerequisites">
          
            <li><a href="/tutorials/intro/">Getting Started with RevBayes and Rev Language Syntax</a></li>
          
          </ul>
        
    </div>
  </div>
  
</blockquote>





<blockquote class="tutorial_files" id="tutorial_files">
    <h2>Data files and scripts</h2>
    
        
        <strong>Other</strong>
        <ul id="other_files">
        
        
        
          <li><a href="/tutorials/intro/scripts/linear_regression.Rev">linear_regression.Rev</a></li>
        
          <li><a href="/tutorials/intro/scripts/linear_regression_generative.Rev">linear_regression_generative.Rev</a></li>
        
          <li><a href="/tutorials/intro/data/x.csv">x.csv</a></li>
        
          <li><a href="/tutorials/intro/data/y.csv">y.csv</a></li>
        
        </ul>
    
</blockquote>


</div>
<h1 class="section" id="overview">Overview</h1>

<p><a href="http://revbayes.com">RevBayes</a> uses a <em>graphical model</em> framework in
which all probabilistic models, including phylogenetic models,
are comprised of modular components that can be assembled in a myriad of ways.
<a href="http://revbayes.com">RevBayes</a> provides a highly flexible language called <code class="language-plaintext highlighter-rouge">Rev</code>
that users employ to specify their own custom graphical models.</p>

<p>This tutorial is intended to be a gentle introduction on how to use <code class="language-plaintext highlighter-rouge">Rev</code> to specify graphical models.
Additionally we’ll cover how to use <code class="language-plaintext highlighter-rouge">Rev</code> to specify the Markov chain Monte Carlo (MCMC) 
algorithms used to perform inference with the model.
We will focus on a simple linear regression example,
and use <a href="http://revbayes.com">RevBayes</a> to estimate the posterior distributions of our parameters.</p>

<h1 class="section" id="why-graphical-models">Why Graphical Models?</h1>

<p><a href="http://revbayes.com">RevBayes</a> is a fundamental reconception of phylogenetic software.
Most phylogenetic software have default settings that allow a user to run an analysis
without truly understanding the assumptions of the model.
<a href="http://revbayes.com">RevBayes</a>, on the other hand, has no defaults and is a complete
blank slate when started. <a href="http://revbayes.com">RevBayes</a> requires users to 
fully specify the model they want to use for their analysis.
This means the learning curve is steep, however there are a number of benefits:</p>

<ol>
  <li>
    <p>Transparency: All the modeling assumptions are explicitly specified in <a href="http://revbayes.com">RevBayes</a>. The <code class="language-plaintext highlighter-rouge">Rev</code> script that runs an analysis makes these assumptions clear and can be easily shared. The assumptions can easily be modified in the <code class="language-plaintext highlighter-rouge">Rev</code> script and then the analysis can be rerun to see how changes affect the results. There is no reliance on “defaults” that may change with different versions of the software.</p>
  </li>
  <li>
    <p>Flexibility: Users are not limited by a small set of models the programmers hard coded, instead users can specify their own custom models uniquely tailored to their hypotheses and datasets.</p>
  </li>
  <li>
    <p>Modularity: Each model component can be combined with others in an endless number of new ways like a LEGO kit. Testing many complex evolutionary hypotheses require tying different models together. For example, suppose you wish to test how the effect of biographic range on trait evolution changes through time. In <a href="http://revbayes.com">RevBayes</a> you could simultaneously infer a time-calibrated phylogeny and estimate biogeography-dependent trait evolution using molecular data, biogeographic range data, and morphological data from both fossils and extant lineages.</p>
  </li>
</ol>

<h1 class="section" id="what-is-a-graphical-model">What is a Graphical Model?</h1>

<figure id="graphicalmodel"><p><img src="figures/graphical_model.png" width="400" /></p>
<figcaption><em>Left: a graphical model in which 
the observed data points $X_i$ are conditionally independent given $\theta$.
Right: the same graphical model using plate notation to represent the $N$ repeated $X_i$.
These graphical models represent the joint probability distribution
\(p(\theta,X_1,\dots,X_N)\).
See <a href="#legend"></a> for a description of the visual symbols.
Image from (missing reference)</em></figcaption>
</figure>

<p>A <em>graphical model</em> is a way to represent a joint multivariate probability distribution as a graph.
Here we mean <em>graph</em> in the mathematical sense of a set of nodes (vertices) and edges.
In a graphical model, the nodes represent variables and the edges represent conditional dependencies among the variables. 
There are three important types
of variables:</p>

<ol>
  <li>Constant nodes: represents a fixed value that will not change.</li>
  <li>Stochastic nodes: represents a random variable with a value drawn from a probability distribution.</li>
  <li>Deterministic nodes: represents a deterministic transformation of the values of other nodes.</li>
</ol>

<p>In the graphical modeling framework observed data is simply a variable with an observed value.
To specify that a node has an observed value associated with it we say that the
node is <em>clamped</em>, or fixed, to the observed value.
<a href="#graphicalmodel"></a> illustrates the graphical model that represents the joint probability distribution</p>

\[\begin{aligned}
p(\theta,\mathcal{D}) = p(\theta) \Big[ \displaystyle\prod^N_{i=1} p(X_i|\theta) \Big],
\end{aligned}\]

<p>where \(\mathcal{D}\) is the vector of observed data points \(X_1,\dots,X_N\).</p>

<p>Nearly any probabilistic model can be represented as a graphical model: neural networks, classification models, time series models, and of course phylogenetic models!
In some literature the terms Bayesian networks, belief networks, or causal networks are sometimes used to refer to graphical models.</p>

<h2 class="subsection" id="visual-representation">Visual Representation</h2>

<p>The statistics literature has developed a rich visual representation for graphical models.
Visually representing graphical models can be useful for communication and pedagogy.
We explain the notation used in the visual representation of these models only briefly 
(see <a href="#legend"></a>),
and enourage readers to see <a class="citation" href="#Hoehna2014b">Höhna et al. (2014)</a> for more details.
As we will discuss below, representing graphical models in computer code 
(using the <code class="language-plaintext highlighter-rouge">Rev</code> language)
will likely be the most useful aspect of graphical models to most readers.</p>

<figure id="legend"><p><img src="figures/graphical_model_legend.png" width="400" /></p>
<figcaption><em>The symbols for a visual representation of a graphical
model. a) Solid squares represent constant nodes, which specify fixed-
valued variables. b) Stochastic nodes are represented by solid circles.
These variables correspond to random variables and may depend on
other variables. c) Deterministic nodes (dotted circles) indicate variables
that are determined by a specific function applied to another variable.
They can be thought of as variable transformations. d) Observed states
are placed in clamped stochastic nodes, represented by gray-shaded
circles. e) Replication over a set of variables is indicated by enclosing
the replicated nodes in a plate (dashed rectangle). f) Tree plates represent 
the different classes of nodes in a phylogeny. 
The tree topology orders the nodes in the tree plate and
may be a constant node (as in this example) or a stochastic node (if the
topology node is a solid circle).
Image and text modified from <a class="citation" href="#Hoehna2014b">Höhna et al. (2014)</a></em></figcaption>
</figure>

<h2 class="subsection" id="phylogenetic-graphical-models">Phylogenetic Graphical Models</h2>

<p>In phylogenetics, observations about different species are not considered independent data points
due to their shared evolutionary history.
So in a phylogenetic probabilistic model the topology of the tree determines the conditional dependencies among variables. This can be represented as a graphical model as in <a href="#phylo_graph"></a> (left).</p>

<p>Phylogenetic models are often highly complex with hundreds of variables. Not only do we model
the conditional dependencies due to shared evolutionary history (the tree topology), 
but we also commonly model character evolution (nucleotide substitution models, etc.),
branching processes that determine the times between speciation events (birth-death processes),
and many other aspects of the evolutionary process.
With graphical models we can think of each part of these models as discrete components that can
be combined in a myriad of ways to assemble different phylogenetic models (<a href="#phylo_graph"></a> right).</p>

<figure id="phylo_graph"><p><img src="figures/phylo_graphical.png" width="400" /><img src="figures/graphical_lego_kit.png" width="400" /></p>
<figcaption><em>Left: In a phylogenetic probabilistic model the topology of the tree determines the conditional dependencies among variables.
Right: A complex phylogenetic model that includes a clock model, a GTR+$\Gamma$ nucleotide substitution model, and a uniform tree topology model. Here the repeated nodes within the tree are represented by a tree plate.
Images from <a class="citation" href="#Hoehna2014b">Höhna et al. (2014)</a></em></figcaption>
</figure>

<h1 class="section" id="probabilistic-programming">Probabilistic Programming</h1>

<p>To describe complex probabilistic models and perform computational tasks with them,
we need a way to formally specify the models in a computer. 
Probabilistic programming languages were designed exactly for this purpose.
A probabilistic programming language is a tool for probabilistic inference that:</p>

<ol>
  <li>formally specifies graphical models, and</li>
  <li>specifies the inference algorithms used with the model.</li>
</ol>

<p>Probabilistic programming languages are being actively developed within
the statistics and machine learning communities.
Some of the most common are <a href="http://mc-stan.org/">Stan</a>, <a href="http://mcmc-jags.sourceforge.net/">JAGS</a>, <a href="http://edwardlib.org/">Edward</a>, and <a href="https://docs.pymc.io/">PyMC3</a>.
While these are all excellent tools, they are all unsuitable for phylogenetic models 
since the tree topology itself must be treated as a random variable to be inferred.</p>

<h2 class="subsection" id="the-rev-probabilistic-programming-language">The <code class="language-plaintext highlighter-rouge">Rev</code> Probabilistic Programming Language</h2>

<p><a href="http://revbayes.com">RevBayes</a> provides its own probabilistic programming language called <code class="language-plaintext highlighter-rouge">Rev</code>.
While <code class="language-plaintext highlighter-rouge">Rev</code> focuses on phylogenetic models, nearly any type of probabilistic
model can be programmed in <code class="language-plaintext highlighter-rouge">Rev</code> making it a highly flexible probabilistic computing environment.
Most <code class="language-plaintext highlighter-rouge">Rev</code> scripts consist of two different parts:</p>

<ol>
  <li>Model specification. This part of the script defines the constant, stochastic, and determinstic nodes that make up the model.</li>
  <li>Inference algorithm specification. This part of the script specifies what sort of inference algorithm we want to use with the model. Typically this is a Markov chain Monte Carlo algorithm, and we need to specify what sort of proposals (or moves) will operate on each variable.</li>
</ol>

<p>In more complex <code class="language-plaintext highlighter-rouge">Rev</code> scripts, these two different elements (model specification and infernence algorithm specification) will be woven together.
In the example for this tutorial we will keep the two parts separate.</p>

<h1 class="section" id="linear-regression-example">Linear Regression Example</h1>

<p>To demonstrate how to use the <code class="language-plaintext highlighter-rouge">Rev</code> language to specify a graphical model,
we will start with a simple non-phylogenetic model.
This tutorial will show both how to specify linear regression
as a graphical model, and how to perform Bayesian inference over
the model using MCMC.</p>

<h2 class="subsection" id="tutorial-format">Tutorial Format</h2>

<p>All command-line text, including all <code class="language-plaintext highlighter-rouge">Rev</code> syntax, are given in <code class="language-plaintext highlighter-rouge">monotype font</code>. Furthermore, blocks of <code class="language-plaintext highlighter-rouge">Rev</code> code that are needed to build the model, specify the analysis, or execute the run are given in separate shaded boxes. For example, we will instruct you to create a new variable called <code class="language-plaintext highlighter-rouge">n</code> that is equal to <code class="language-plaintext highlighter-rouge">10</code> using the <code class="language-plaintext highlighter-rouge">&lt;-</code> operator like this:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>n &lt;- 10
</code></pre></div></div>

<h2 class="subsection" id="setup-your-files">Setup Your Files</h2>

<p>Make yourself familiar with the example script called <a href="scripts/linear_regression.Rev"><code class="language-plaintext highlighter-rouge">linear_regression.Rev</code></a> which shows the code for the following sections. Then, start a new and empty script in your text editor and follow each step provided as below. Name the script file <code class="language-plaintext highlighter-rouge">my_linear_regression.Rev</code> or anything you’d like.</p>

<p>You’ll also want to download the <a href="data/x.csv"><code class="language-plaintext highlighter-rouge">x.csv</code></a> and <a href="data/y.csv"><code class="language-plaintext highlighter-rouge">y.csv</code></a> data files and place them in a <code class="language-plaintext highlighter-rouge">data</code> directory.</p>

<h2 class="subsection" id="linear-regression-as-a-graphical-model">Linear Regression as a Graphical Model</h2>

<figure id="linear"><p><img src="figures/linear_regression.png" width="500" /></p>
<figcaption><em>The observed data used in the linear regression example.</em></figcaption>
</figure>

<p>Suppose we observed the data shown in <a href="#linear"></a>.
We might hypothesize that $x$ and $y$ are related through the linear
regression model</p>

\[\begin{aligned}
y = \beta x + \alpha + \epsilon.
\end{aligned}\]

<p>In this model $\beta$ and $\alpha$ are the regression variables (slope and y-intercept, respectively) 
and $\epsilon$ is an error or noise term.
We can formulate this as the graphical model</p>

\[\begin{aligned}
\mu_y := \beta x + \alpha
\end{aligned}\]

\[\begin{aligned}
y \sim \text{Normal}(\mu_y, \sigma_{\epsilon}).
\end{aligned}\]

<p>Here $\mu_y$ is a <em>deterministic</em> variable, it is determined by whatever the values
of $\beta$ and $\alpha$ are. We use the $:=$ assignment operator to designate
that $\mu_y$ is deterministic. The error or noise term $\epsilon$ is represented
as a normal distribution where the mean equals $\mu_y$ and the 
standard deviation is $\sigma_{\epsilon}$.
$y$ is a stochastic variable, it has a value that is drawn from a probability distribution.
This is designated by using the $\sim$ assignment operator.
Since we have observed values for $y$, we will <em>clamp</em> $y$ to those observed values.</p>

<h2 class="subsection" id="bayesian-linear-regression">Bayesian Linear Regression</h2>

<p>In our linear regression model $\beta$, $\alpha$, and $\sigma_{\epsilon}$ 
are the free variables we wish to estimate.
To perform Bayesian inference, we need some priors!</p>

\[\begin{aligned}
\beta \sim \text{Normal}(\mu=0, \sigma^2=1)
\end{aligned}\]

\[\begin{aligned}
\alpha \sim \text{Normal}(\mu=0, \sigma^2=1)
\end{aligned}\]

\[\begin{aligned}
\sigma_{\epsilon} \sim \text{Exponential}(\lambda=1)
\end{aligned}\]

<p>Again, these are stochastic variables, so we use the $\sim$ assignment operator.
For now we will accept these as decent uninformative priors.
Later in the tutorial we will discuss how the choice of a prior 
can affect the outcome of the analysis.</p>

<blockquote class="instruction">
  <p><strong>Exercise:</strong> <br /><br />
Using the sticks-and-arrows visual symbols explained in <a href="#legend"></a>, draw 
the linear regression graphical model. See the answer in the expandable box below.</p>
</blockquote>

<blockquote class="aside"><h2>Answer: Visual Representation of the Linear Regression Model</h2><figure id="linear_gm"><p><img src="figures/tikz/lr.png" width="500" /></p>
<figcaption><em>Visual representation of the linear regression graphical model.
The plate (dashed rectangle) around $x_i$, $\mu_{yi}$ and $y_i$ represent
the repeated variables for all the observed points.
$y_i$ is a clamped (observed) stochastic node, so it is shaded.
$\mu_{yi}$ is a deterministic node, so it is dashed.
Here we treat $x_i$ as a constant node, so it is square.
$\alpha$, $\beta$, and $\sigma$ are the stochastic variables we wish
to estimate, and each of them are assigned priors distributions which
have constant parameter values (the squares on the top row of the figure).</em></figcaption>
</figure>
</blockquote>

<h2 class="subsection" id="specifying-the-model-in-rev">Specifying the Model in <code class="language-plaintext highlighter-rouge">Rev</code></h2>

<p>Remember that graphical models are made up of three types of nodes: stochastic, constant, and deterministic nodes.
In <code class="language-plaintext highlighter-rouge">Rev</code> we specify the type of node by using a specific assignment operator:</p>
<ul>
  <li>Stochastic node: <code class="language-plaintext highlighter-rouge">n ~ dnNormal(0, 1)</code></li>
  <li>Constant node: <code class="language-plaintext highlighter-rouge">n &lt;- 5</code></li>
  <li>Deterministic node: <code class="language-plaintext highlighter-rouge">n := m + 5</code></li>
</ul>

<p>We will use each of these assignment operators to set up the linear regression model.</p>

<p>First, we read in the observed data as constant nodes:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x_obs &lt;- readDataDelimitedFile(file="data/x.csv", header=FALSE, delimiter=",")[1]
y_obs &lt;- readDataDelimitedFile(file="data/y.csv", header=FALSE, delimiter=",")[1]
</code></pre></div></div>
<p>Take a look at <code class="language-plaintext highlighter-rouge">x_obs</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>x_obs
</code></pre></div></div>
<p>This is the vector of x-coordinates for the points plotted in <a href="#linear"></a>.</p>

<p>Now we will specify the prior distributions for the stochastic nodes.
These are the variables that we will estimate:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>beta ~ dnNormal(0, 1)
alpha ~ dnNormal(0, 1)
sigma ~ dnExponential(1)
</code></pre></div></div>

<p>Now, for each observed value in <code class="language-plaintext highlighter-rouge">x_obs</code>
we will create a deterministic node for <code class="language-plaintext highlighter-rouge">mu_y</code> and a stochastic node for <code class="language-plaintext highlighter-rouge">y</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for (i in 1:x_obs.size()) {
    mu_y[i] := (beta * x_obs[i]) + alpha
    y[i] ~ dnNormal(mu_y[i], sigma)
}
</code></pre></div></div>
<p>Take a look at <code class="language-plaintext highlighter-rouge">y</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>y
</code></pre></div></div>
<p>This produces a vector of simulated values of <code class="language-plaintext highlighter-rouge">y</code>!
We have specified a model that describes the process that generates <code class="language-plaintext highlighter-rouge">y</code>
conditioned on the observed values of <code class="language-plaintext highlighter-rouge">x</code>.
We have not clamped, or fixed, the observed values <code class="language-plaintext highlighter-rouge">y_obs</code> to the stochastic nodes <code class="language-plaintext highlighter-rouge">y</code>.
In <code class="language-plaintext highlighter-rouge">Rev</code> all models can be used to both simulate new values and, when clamped to observed values,
perform parameter inference.</p>

<p>In this case we are not interested in simulating new values of <code class="language-plaintext highlighter-rouge">y</code>, but instead
we want to estimate our linear regression parameters. So let’s modify the above code
to clamp the observed values to <code class="language-plaintext highlighter-rouge">y</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>for (i in 1:x_obs.size()) {
    mu_y[i] := (beta * x_obs[i]) + alpha
    y[i] ~ dnNormal(mu_y[i], sigma)
    y[i].clamp(y_obs[i])
}
</code></pre></div></div>
<p>Note that we have now clamped each observed value <code class="language-plaintext highlighter-rouge">y_obs</code> to each stochastic node <code class="language-plaintext highlighter-rouge">y</code>.</p>

<p>We have now fully specified the model, so we can begin specifying the inference
algorithm.</p>

<h2 class="subsection" id="setting-up-mcmc-in-rev">Setting up MCMC in <code class="language-plaintext highlighter-rouge">Rev</code></h2>

<p>Here we will use the Metropolis-Hastings MCMC algorithm <a class="citation" href="#Metropolis1953">(Metropolis et al. 1953; Hastings 1970)</a> 
to perform parameter estimation.
We focus here on providing a simple overview of how to set up and tweak MCMC in RevBayes,
for a more in depth introduction to MCMC please see the <a href="/tutorials/mcmc/">Introduction to Markov chain Monte Carlo (MCMC) Sampling</a> tutorial.</p>

<p>The first step in setting up our MCMC algorithm is wrapping the entire model
into a single variable:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mymodel = model(beta)
</code></pre></div></div>
<p>Since our model is a graph in which all the model nodes are connected,
we can use any model variable and RevBayes will traverse the graph to copy
the entire model into the variable <code class="language-plaintext highlighter-rouge">mymodel</code>.</p>

<p>Note that we used the <code class="language-plaintext highlighter-rouge">=</code> assignment operator. This means that the variable
<code class="language-plaintext highlighter-rouge">mymodel</code> is <em>not</em> part of the graphical model – it is not a stochastic, constant, or deterministic
node. We call this a <code class="language-plaintext highlighter-rouge">Rev</code> workspace variable. Workspace variables
are utility variables that we use for any programming task that 
is not specifically defining the model.
Note, that unlike in <code class="language-plaintext highlighter-rouge">R</code>, in <code class="language-plaintext highlighter-rouge">Rev</code> the <code class="language-plaintext highlighter-rouge">=</code> and <code class="language-plaintext highlighter-rouge">&lt;-</code> assignment operators have very different functions!</p>

<p>To sample different values of each variable, we must assign
an MCMC move to each variable. Each MCMC move will propose new values
of each parameter. We have three variables,
so we will have three moves which we will save in a
vector called <code class="language-plaintext highlighter-rouge">moves</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[1] = mvSlide(beta, delta=0.001, weight=1)
moves[2] = mvSlide(alpha, delta=0.001, weight=1)
moves[3] = mvSlide(sigma, delta=0.001, weight=1)
</code></pre></div></div>
<p>Here we used simple slide moves for each variable. 
The slide move proposes new values for the variable by “sliding” its value within a small window
determined by the <code class="language-plaintext highlighter-rouge">delta</code> argument.
RevBayes provides many other types of moves that you will see in other tutorials.
We set the <code class="language-plaintext highlighter-rouge">weight</code> of each move to 1, which means that each
move will be performed on average once per MCMC iteration.</p>

<p>Next, we need to set up some monitors that will sample values during the MCMC.
We will use two monitors which we save into a vector called <code class="language-plaintext highlighter-rouge">monitors</code>.
The first monitor <code class="language-plaintext highlighter-rouge">mnScreen</code> prints out values to the screen,
and the second monitor <code class="language-plaintext highlighter-rouge">mnModel</code> prints a log file.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitors[1] = mnScreen()
monitors[2] = mnModel(filename="output/linear_regression.log")
</code></pre></div></div>
<p>RevBayes provides many other monitors that can be useful for different types of analyses,
but these are sufficient for this example.</p>

<p>We can now pass the model, moves, and monitors into the <code class="language-plaintext highlighter-rouge">mcmc</code> function
to finalize our analysis.
Then we use the <code class="language-plaintext highlighter-rouge">run</code> member method to run the MCMC for 10000 iterations.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mymcmc = mcmc(mymodel, moves, monitors)
mymcmc.run(10000)
quit()
</code></pre></div></div>
<p>Note that we included the <code class="language-plaintext highlighter-rouge">quit()</code> command so that RevBayes will automatically quit
after the MCMC has finished running.</p>

<h1 class="section" id="improving-mcmc-mixing">Improving MCMC Mixing</h1>

<blockquote class="instruction">
  <p><strong>Exercise:</strong> <br /><br />
Now open the file <code class="language-plaintext highlighter-rouge">output/linear_regression.log</code> in Tracer.</p>
</blockquote>
<p>You will notice that the MCMC analysis did not converge well:</p>
<figure id="bad"><p><img src="figures/beta-bad.png" width="400" /></p>
<figcaption><em>The MCMC trace for the <code class="language-plaintext highlighter-rouge">beta</code> parameter. This analysis never converged.</em></figcaption>
</figure>

<p>We can fix this by modifying the MCMC moves we use.
Let’s use a larger sliding window (the <code class="language-plaintext highlighter-rouge">delta</code> argument in <code class="language-plaintext highlighter-rouge">mvSlide</code>).
We will also increase the <code class="language-plaintext highlighter-rouge">weight</code> of each move to 5.
This means that each move will be now be performed on average 5 times
per MCMC iteration.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>moves[1] = mvSlide(beta, delta=1, weight=5)
moves[2] = mvSlide(alpha, delta=1, weight=5)
moves[3] = mvSlide(sigma, delta=1, weight=5)
</code></pre></div></div>
<blockquote class="instruction">
  <p><strong>Exercise:</strong> <br /><br />
Rerun the MCMC analysis with these new moves and view the log file in Tracer.</p>
</blockquote>
<p>This analysis looks much better:</p>
<figure id="good"><p><img src="figures/beta-good.png" width="400" /><img src="figures/param-estimates.png" width="400" /></p>
<figcaption><em>Left: The MCMC trace for the <code class="language-plaintext highlighter-rouge">beta</code> parameter. This analysis has adequately converged;
all parameter values have ESS values over 200.
Right: Posterior parameter estimates from the converged MCMC analysis.
The y-intercept ($\alpha$) was estimated to be about -2 and the slope 
($\beta$) was estimated to be about 0.5. 
This closely matches what is observed in <a href="#linear"></a>.
Moreover, -2 and 0.5 were the true values used to simulate the data.</em></figcaption>
</figure>

<h1 class="section" id="prior-sensitivity">Prior Sensitivity</h1>

<figure id="priors"><p><img src="figures/normal.png" width="400" /></p>
<figcaption><em>Normal distributions with different values of the standard deviation.</em></figcaption>
</figure>

<p>Prior distributions are a way to mathematically formalize our
prior knowledge.
We used normal distributions as priors for $\alpha$ and $\beta$.
How did we pick these distributions? 
<a href="#priors"></a> illustrates the normal distribution with different
values for the standard deviation.
Using a smaller standard deviation (0.1) places most of the density
close to 0. 
This sort of prior is appropriate only if we have prior information
that the parameter’s true value is close to 0, so we can call this
an <em>informative</em> prior.
Using a large standard deviation (10.0) is a highly <em>uninformative</em> prior.
The density is diffuse and nearly uniform, allowing for a wide range of values.
This is appropriate if we have very little idea what the true value of
the parameter is.</p>

<p>In <a href="http://revbayes.com">RevBayes</a> it is easy to modify the priors used in an analysis and rerun the analysis.</p>
<blockquote class="instruction">
  <p><strong>Exercise:</strong> <br /><br />
Try rerunning the linear regression exercise using highly informative priors (standard deviation set to 0.1) on <code class="language-plaintext highlighter-rouge">beta</code> and <code class="language-plaintext highlighter-rouge">alpha</code> as shown below.</p>
</blockquote>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>beta ~ dnNormal(0, 0.1)
alpha ~ dnNormal(0, 0.1)
</code></pre></div></div>
<p><a href="#bad-priors"></a> shows the posterior estimates when using these priors.
Compare those results with those shown in <a href="#good"></a>.
Using informative priors that are incorrect can badly bias the results.</p>

<figure id="bad-priors"><p><img src="figures/priors.png" width="400" /></p>
<figcaption><em>Biased posterior parameter estimates when using overly informative priors.
The true values were $\alpha = -2$, $\beta = 0.5$, and $\sigma = 0.25$.</em></figcaption>
</figure>

<blockquote class="instruction">
  <p><strong>Exercise:</strong> <br /><br />
Try running the analysis again with highly uninformative priors (10.0).</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>beta ~ dnNormal(0, 10.0)
alpha ~ dnNormal(0, 10.0)
</code></pre></div></div>
<p>These results are highly similar to our original estimates
shown in <a href="#good"></a>. Our original priors (that had a standard deviation of 1.0)
did not introduce any bias.
Typically the trade off is between informative priors that may introduce bias
and uninformative priors that may increase the variance (uncertainty) of our
estimates.</p>

<h1 class="section" id="generative-vs-discriminative-models">Generative vs Discriminative Models</h1>

<p>Probabilistic models can be understood as either <em>discriminative</em> or <em>generative</em> models.
The distinction between the two can be useful in phylogenetics
where different analyses often make use of these different types of models.
<a href="http://revbayes.com">RevBayes</a> enables us to specify both types of models.</p>

<h3 id="discriminative-models">Discriminative Models</h3>

<p>Discriminative (or conditional) models
involve a response variable conditioned on a predictor variable.
The model represents the conditional distribution $p(y|x)$
and so makes fewer assumptions about the data: 
it is not necessary to specify $p(x)$.
The linear regression example we coded in <code class="language-plaintext highlighter-rouge">Rev</code> was a discriminative model
because it conditioned on the observed values of $x$. In other words
the model could simulate values of $y$ conditioned on the observed values of $x$,
but it could not simulate values of $x$.</p>

<p>In phylogenetics we often use discriminative models when we condition over a fixed tree (or set of trees):</p>
<ul>
  <li>estimating divergence times over a fixed topology</li>
  <li>estimating ancestral states on a fixed tree</li>
  <li>estimating shifts in diversification rates over a fixed tree</li>
</ul>

<p>We can set up all these discriminative models in <a href="http://revbayes.com">RevBayes</a>.</p>

<h3 id="generative-models">Generative Models</h3>

<p>Generative models
model the entire process used to generate the data.
So these models represent the joint distribution $p(x, y)$,
and therefore they must make more assumptions about the data: 
we need to define $p(x)$.
This allows for a richer representation of the relations between variables.
Additionally these models are more powerful; 
they allow us to compute $p(y|x)$ or $p(x|y)$
and to simulate both $x$ and $y$.</p>

<p>In phylogenetics we use fully generative models when we:</p>
<ul>
  <li>jointly estimate divergence times and the tree topology</li>
  <li>jointly estimate ancestral states and the tree</li>
  <li>jointly estimate shifting diversification rates and the tree</li>
</ul>

<p><a href="http://revbayes.com">RevBayes</a> is unique because it allows us to specify both highly complex fully generative models
as well as their more simple discriminative forms.</p>

<h3 id="a-generative-linear-regression-model">A Generative Linear Regression Model</h3>

<p>A fully generative linear regression model enables us to learn something about $x$, for example the mean
and standard deviation, which we don’t get from the discriminative form.
With the generative model:</p>
<ul>
  <li>we can simulate values of both $x$ and $y$,</li>
  <li>both $x$ and $y$ will need to be clamped to the observed data,</li>
  <li>and we will need to specify a prior distribution for $x$.</li>
</ul>

<blockquote class="instruction">
  <p><strong>Exercise:</strong> <br /><br />
Reformulate our linear regression example so that it is a fully generative model:</p>
  <ol>
    <li>Draw the sticks-and-arrows diagram for a generative model and compare it to the discriminative form. See the expandable box for one solution.</li>
    <li>Code up the model in <code class="language-plaintext highlighter-rouge">Rev</code> and run MCMC. A solution is provided in <a href="scripts/linear_regression_generative.Rev"><code class="language-plaintext highlighter-rouge">linear_regression_generative.Rev</code></a> if you get stuck.</li>
  </ol>
</blockquote>

<blockquote class="aside"><h2>Answer: Visual Representation of the Generative Linear Regression Model</h2><figure id="linear_gm_gen"><p><img src="figures/tikz/lr_generative.png" width="600" /></p>
<figcaption><em>Visual representation of the generative linear regression graphical model.
Compare this to <a href="#linear_gm"></a>.
The major difference is we now treat $x_i$ as a clamped (observed)
stochastic node.
Additionally, we now estimate $\mu_x$ and $\sigma_x$ as stochastic variables.</em></figcaption>
</figure>
</blockquote>

<h3 id="conclusion">Conclusion</h3>

<p><a href="http://revbayes.com">RevBayes</a> gives evolutionary biologists the tools to formalize their 
hypotheses as custom graphical models that represent the specific process
that generated their data.
This enables many evolutionary hypotheses
to now be tested in a rigorous and quantitative approach.
Hopefully this tutorial will help readers develop their own custom models
and not use defaults ever again!</p>

<ol class="bibliography"><li><span id="Hastings1970">Hastings W.K. 1970. Monte Carlo Sampling Methods Using Markov Chains and Their Applications. Biometrika. 57:97–109.</span>

</li>
<li><span id="Hoehna2014b">Höhna S., Heath T.A., Boussau B., Landis M.J., Ronquist F., Huelsenbeck J.P. 2014. Probabilistic Graphical Model Representation in Phylogenetics. Systematic Biology. 63:753–771.</span>

<a href="https://doi.org/10.1093/sysbio/syu039">10.1093/sysbio/syu039</a>

</li>
<li><span id="Metropolis1953">Metropolis N., Rosenbluth A.W., Rosenbluth M.N., Teller A.H., Teller E. 1953. Equation of State Calculations by Fast Computing Machines. Journal of Chemical Physics. 21:1087–1092.</span>

<a href="https://doi.org/10.1063/1.1699114">10.1063/1.1699114</a>

</li></ol>

<script type="text/javascript">
var _ol = document.querySelectorAll('ol');
for (var i = 0, elem_ol; elem_ol = _ol[i]; i++) {
	if ( elem_ol.classList == "bibliography" ) {
		var _li = elem_ol.getElementsByTagName("li");
		//for (var j = 0, elem_li; elem_li = _li[j]; j++)
		//{
		//	elem_li.innerHTML = elem_li.innerHTML.replace(/(https?:\/\/)([^\s<]+)/,"<a href=\"$1$2\">$2");
		//}
		if(_li.length > 0)
			elem_ol.outerHTML = "<h2 class='references'>References</h2><hr class='references'>"+elem_ol.outerHTML
	}
}
</script>

      </div>
      <br>
<footer>
  <div class="container">
  <div class="row">
    <div class="col-sm-12" align="center">
      <a href="https://github.com/revbayes">GitHub</a> | <a href="/license">License</a> | <a href="/citation">Citation</a> | <a href="https://groups.google.com/forum/#!forum/revbayes-users">Users Forum</a>
    </div>
  </div>
  <br>
  </div>
</footer>

    </div>
    <script src="/assets/js/vendor/jquery.min.js"></script>
<script src="/assets/js/vendor/FileSaver.min.js"></script>
<script src="/assets/js/vendor/jszip.min.js"></script>
<script src="/assets/js/vendor/bootstrap.min.js"></script>

<script type="text/javascript">
// Add default language
$(":not(code).highlighter-rouge").each(function() {
  
  if( this.classList == "highlighter-rouge") {
    this.classList = "Rev highlighter-rouge";
  }
  
});
// $("code.highlighter-rouge").each(function() {
//   
//   if( this.classList == "highlighter-rouge") {
//       this.classList = "Rev highlighter-rouge";
//   }
//   
// });
</script>
<script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
    });
    MathJax.Hub.Queue(function () {
      $(".aside").each(function() {
          $("div .MathJax", this).hide();
      });
    });
</script>
<script src="/assets/js/base.js"></script>

    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0Y03X9Q2TJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-0Y03X9Q2TJ');
</script>

  </body>
</html>
